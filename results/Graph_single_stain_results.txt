CD138
Epoch 0/50
----------
Training batch 0/107- batch 0, loss: 0.6903, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.6714, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.6822, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.7019, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.7063, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.6503, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.7064, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.6655, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.6272, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.5374, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.9270, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 0, train_loss: 0.0078, train_accuracy: 0.4579
class 0: acc 0.2857142857142857, correct 14/49
class 1: acc 0.603448275862069, correct 35/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5899, AUC: 0.8479, Accuracy: 0.7391
class 0: acc 0.47058823529411764, correct 8/17
class 1: acc 0.896551724137931, correct 26/29
              precision    recall  f1-score   support
0              0.727273  0.470588  0.571429  17.00000
1              0.742857  0.896552  0.812500  29.00000
accuracy       0.739130  0.739130  0.739130   0.73913
macro avg      0.735065  0.683570  0.691964  46.00000
weighted avg   0.737098  0.739130  0.723408  46.00000
[[ 8  9]
 [ 3 26]]
Sensitivity:  0.896551724137931
Specificity:  0.47058823529411764
Epoch 1/50
----------
Training batch 0/107- batch 0, loss: 0.9365, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.6705, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.7751, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.6447, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.6076, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0261, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.4631, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0004, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0349, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.2061, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.4960, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 1, train_loss: 0.0053, train_accuracy: 0.7944
class 0: acc 0.7959183673469388, correct 39/49
class 1: acc 0.7931034482758621, correct 46/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4641, AUC: 0.8864, Accuracy: 0.7826
class 0: acc 0.6470588235294118, correct 11/17
class 1: acc 0.8620689655172413, correct 25/29
              precision    recall  f1-score    support
0              0.733333  0.647059  0.687500  17.000000
1              0.806452  0.862069  0.833333  29.000000
accuracy       0.782609  0.782609  0.782609   0.782609
macro avg      0.769892  0.754564  0.760417  46.000000
weighted avg   0.779430  0.782609  0.779438  46.000000
[[11  6]
 [ 4 25]]
Sensitivity:  0.8620689655172413
Specificity:  0.6470588235294118
Epoch 2/50
----------
Training batch 0/107- batch 0, loss: 1.0199, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.4682, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.4340, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.3265, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.1810, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0075, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.1406, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0005, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0261, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.2130, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.7659, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 2, train_loss: 0.0081, train_accuracy: 0.8037
class 0: acc 0.6938775510204082, correct 34/49
class 1: acc 0.896551724137931, correct 52/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5090, AUC: 0.9168, Accuracy: 0.7391
class 0: acc 0.29411764705882354, correct 5/17
class 1: acc 1.0, correct 29/29
              precision    recall  f1-score   support
0              1.000000  0.294118  0.454545  17.00000
1              0.707317  1.000000  0.828571  29.00000
accuracy       0.739130  0.739130  0.739130   0.73913
macro avg      0.853659  0.647059  0.641558  46.00000
weighted avg   0.815483  0.739130  0.690344  46.00000
[[ 5 12]
 [ 0 29]]
Sensitivity:  1.0
Specificity:  0.29411764705882354
Epoch 3/50
----------
Training batch 0/107- batch 0, loss: 1.0360, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.7739, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.3549, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.2664, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0316, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1034, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0532, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0255, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0447, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0963, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.2754, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 3, train_loss: 0.0039, train_accuracy: 0.8037
class 0: acc 0.7142857142857143, correct 35/49
class 1: acc 0.8793103448275862, correct 51/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4024, AUC: 0.9148, Accuracy: 0.8043
class 0: acc 0.5882352941176471, correct 10/17
class 1: acc 0.9310344827586207, correct 27/29
              precision    recall  f1-score    support
0              0.833333  0.588235  0.689655  17.000000
1              0.794118  0.931034  0.857143  29.000000
accuracy       0.804348  0.804348  0.804348   0.804348
macro avg      0.813725  0.759635  0.773399  46.000000
weighted avg   0.808610  0.804348  0.795245  46.000000
[[10  7]
 [ 2 27]]
Sensitivity:  0.9310344827586207
Specificity:  0.5882352941176471
Epoch 4/50
----------
Training batch 0/107- batch 0, loss: 1.1847, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.6472, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1993, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1564, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.1050, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0181, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.1193, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0003, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0349, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0836, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.1207, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 4, train_loss: 0.0024, train_accuracy: 0.8879
class 0: acc 0.8979591836734694, correct 44/49
class 1: acc 0.8793103448275862, correct 51/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.3770, AUC: 0.9168, Accuracy: 0.8478
class 0: acc 0.7647058823529411, correct 13/17
class 1: acc 0.896551724137931, correct 26/29
              precision    recall  f1-score    support
0              0.812500  0.764706  0.787879  17.000000
1              0.866667  0.896552  0.881356  29.000000
accuracy       0.847826  0.847826  0.847826   0.847826
macro avg      0.839583  0.830629  0.834617  46.000000
weighted avg   0.846649  0.847826  0.846810  46.000000
[[13  4]
 [ 3 26]]
Sensitivity:  0.896551724137931
Specificity:  0.7647058823529411
Epoch 5/50
----------
Training batch 0/107- batch 0, loss: 0.7534, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.4788, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1986, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1369, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0663, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0247, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0853, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0008, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0165, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.1231, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.1477, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 5, train_loss: 0.0049, train_accuracy: 0.8505
class 0: acc 0.8367346938775511, correct 41/49
class 1: acc 0.8620689655172413, correct 50/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.3872, AUC: 0.9108, Accuracy: 0.8478
class 0: acc 0.7058823529411765, correct 12/17
class 1: acc 0.9310344827586207, correct 27/29
              precision    recall  f1-score    support
0              0.857143  0.705882  0.774194  17.000000
1              0.843750  0.931034  0.885246  29.000000
accuracy       0.847826  0.847826  0.847826   0.847826
macro avg      0.850446  0.818458  0.829720  46.000000
weighted avg   0.848700  0.847826  0.844205  46.000000
[[12  5]
 [ 2 27]]
Sensitivity:  0.9310344827586207
Specificity:  0.7058823529411765
Epoch 6/50
----------
Training batch 0/107- batch 0, loss: 1.0353, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.5175, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1611, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1107, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0459, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0207, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0447, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0060, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0524, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.1312, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.1047, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 6, train_loss: 0.0079, train_accuracy: 0.8785
class 0: acc 0.8775510204081632, correct 43/49
class 1: acc 0.8793103448275862, correct 51/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4339, AUC: 0.9087, Accuracy: 0.7609
class 0: acc 0.4117647058823529, correct 7/17
class 1: acc 0.9655172413793104, correct 28/29
              precision    recall  f1-score   support
0              0.875000  0.411765  0.560000  17.00000
1              0.736842  0.965517  0.835821  29.00000
accuracy       0.760870  0.760870  0.760870   0.76087
macro avg      0.805921  0.688641  0.697910  46.00000
weighted avg   0.787900  0.760870  0.733887  46.00000
[[ 7 10]
 [ 1 28]]
Sensitivity:  0.9655172413793104
Specificity:  0.4117647058823529
Epoch 7/50
----------
Training batch 0/107- batch 0, loss: 1.7556, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.9387, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1967, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1479, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0386, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0213, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0548, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0011, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0285, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0682, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.1233, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 7, train_loss: 0.0082, train_accuracy: 0.8785
class 0: acc 0.8367346938775511, correct 41/49
class 1: acc 0.9137931034482759, correct 53/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4028, AUC: 0.9128, Accuracy: 0.8043
class 0: acc 0.5294117647058824, correct 9/17
class 1: acc 0.9655172413793104, correct 28/29
              precision    recall  f1-score    support
0              0.900000  0.529412  0.666667  17.000000
1              0.777778  0.965517  0.861538  29.000000
accuracy       0.804348  0.804348  0.804348   0.804348
macro avg      0.838889  0.747465  0.764103  46.000000
weighted avg   0.822947  0.804348  0.789521  46.000000
[[ 9  8]
 [ 1 28]]
Sensitivity:  0.9655172413793104
Specificity:  0.5294117647058824
Epoch 8/50
----------
Training batch 0/107- batch 0, loss: 1.3215, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.5579, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1034, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0618, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0382, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0293, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0612, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0042, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0177, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0542, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0976, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 8, train_loss: 0.0056, train_accuracy: 0.9159
class 0: acc 0.9183673469387755, correct 45/49
class 1: acc 0.9137931034482759, correct 53/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4067, AUC: 0.9128, Accuracy: 0.8043
class 0: acc 0.5882352941176471, correct 10/17
class 1: acc 0.9310344827586207, correct 27/29
              precision    recall  f1-score    support
0              0.833333  0.588235  0.689655  17.000000
1              0.794118  0.931034  0.857143  29.000000
accuracy       0.804348  0.804348  0.804348   0.804348
macro avg      0.813725  0.759635  0.773399  46.000000
weighted avg   0.808610  0.804348  0.795245  46.000000
[[10  7]
 [ 2 27]]
Sensitivity:  0.9310344827586207
Specificity:  0.5882352941176471
Epoch 9/50
----------
Training batch 0/107- batch 0, loss: 1.4775, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.8709, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1461, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1093, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0420, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0109, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0423, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0010, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0081, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.1166, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0328, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 9, train_loss: 0.0032, train_accuracy: 0.9252
class 0: acc 0.9183673469387755, correct 45/49
class 1: acc 0.9310344827586207, correct 54/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.3655, AUC: 0.9229, Accuracy: 0.8261
class 0: acc 0.6470588235294118, correct 11/17
class 1: acc 0.9310344827586207, correct 27/29
              precision    recall  f1-score    support
0              0.846154  0.647059  0.733333  17.000000
1              0.818182  0.931034  0.870968  29.000000
accuracy       0.826087  0.826087  0.826087   0.826087
macro avg      0.832168  0.789047  0.802151  46.000000
weighted avg   0.828519  0.826087  0.820103  46.000000
[[11  6]
 [ 2 27]]
Sensitivity:  0.9310344827586207
Specificity:  0.6470588235294118
Epoch 10/50
----------
Training batch 0/107- batch 0, loss: 1.3263, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.2197, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0924, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1308, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0237, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0021, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0321, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0002, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0065, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0459, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 1.5133, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 10, train_loss: 0.0077, train_accuracy: 0.8785
class 0: acc 0.8163265306122449, correct 40/49
class 1: acc 0.9310344827586207, correct 54/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5085, AUC: 0.8986, Accuracy: 0.6957
class 0: acc 0.17647058823529413, correct 3/17
class 1: acc 1.0, correct 29/29
              precision    recall  f1-score    support
0              1.000000  0.176471  0.300000  17.000000
1              0.674419  1.000000  0.805556  29.000000
accuracy       0.695652  0.695652  0.695652   0.695652
macro avg      0.837209  0.588235  0.552778  46.000000
weighted avg   0.794742  0.695652  0.618720  46.000000
[[ 3 14]
 [ 0 29]]
Sensitivity:  1.0
Specificity:  0.17647058823529413
Epoch 11/50
----------
Training batch 0/107- batch 0, loss: 1.2368, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.8334, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.2864, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.2128, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0455, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0510, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0365, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0082, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0274, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0967, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0486, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 11, train_loss: 0.0007, train_accuracy: 0.9065
class 0: acc 0.8775510204081632, correct 43/49
class 1: acc 0.9310344827586207, correct 54/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4120, AUC: 0.9047, Accuracy: 0.8261
class 0: acc 0.7058823529411765, correct 12/17
class 1: acc 0.896551724137931, correct 26/29
              precision    recall  f1-score    support
0              0.800000  0.705882  0.750000  17.000000
1              0.838710  0.896552  0.866667  29.000000
accuracy       0.826087  0.826087  0.826087   0.826087
macro avg      0.819355  0.801217  0.808333  46.000000
weighted avg   0.824404  0.826087  0.823551  46.000000
[[12  5]
 [ 3 26]]
Sensitivity:  0.896551724137931
Specificity:  0.7058823529411765
Epoch 12/50
----------
Training batch 0/107- batch 0, loss: 1.0398, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 1.0521, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1186, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1593, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0630, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0027, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0740, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0012, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0173, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.1620, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0732, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 12, train_loss: 0.0013, train_accuracy: 0.9065
class 0: acc 0.9183673469387755, correct 45/49
class 1: acc 0.896551724137931, correct 52/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.3903, AUC: 0.9108, Accuracy: 0.8261
class 0: acc 0.7647058823529411, correct 13/17
class 1: acc 0.8620689655172413, correct 25/29
              precision    recall  f1-score    support
0              0.764706  0.764706  0.764706  17.000000
1              0.862069  0.862069  0.862069  29.000000
accuracy       0.826087  0.826087  0.826087   0.826087
macro avg      0.813387  0.813387  0.813387  46.000000
weighted avg   0.826087  0.826087  0.826087  46.000000
[[13  4]
 [ 4 25]]
Sensitivity:  0.8620689655172413
Specificity:  0.7647058823529411
Epoch 13/50
----------
Training batch 0/107- batch 0, loss: 0.3570, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.2413, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1580, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1322, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0258, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0076, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0596, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0392, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.1339, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0321, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 13, train_loss: 0.0018, train_accuracy: 0.9252
class 0: acc 0.9591836734693877, correct 47/49
class 1: acc 0.896551724137931, correct 52/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.3915, AUC: 0.9087, Accuracy: 0.8261
class 0: acc 0.7058823529411765, correct 12/17
class 1: acc 0.896551724137931, correct 26/29
              precision    recall  f1-score    support
0              0.800000  0.705882  0.750000  17.000000
1              0.838710  0.896552  0.866667  29.000000
accuracy       0.826087  0.826087  0.826087   0.826087
macro avg      0.819355  0.801217  0.808333  46.000000
weighted avg   0.824404  0.826087  0.823551  46.000000
[[12  5]
 [ 3 26]]
Sensitivity:  0.896551724137931
Specificity:  0.7058823529411765
Epoch 14/50
----------
Training batch 0/107- batch 0, loss: 0.8891, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1194, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0729, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1924, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0599, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0007, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0485, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0098, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.2880, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0683, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 14, train_loss: 0.0028, train_accuracy: 0.9159
class 0: acc 0.9183673469387755, correct 45/49
class 1: acc 0.9137931034482759, correct 53/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.3764, AUC: 0.9168, Accuracy: 0.8478
class 0: acc 0.7058823529411765, correct 12/17
class 1: acc 0.9310344827586207, correct 27/29
              precision    recall  f1-score    support
0              0.857143  0.705882  0.774194  17.000000
1              0.843750  0.931034  0.885246  29.000000
accuracy       0.847826  0.847826  0.847826   0.847826
macro avg      0.850446  0.818458  0.829720  46.000000
weighted avg   0.848700  0.847826  0.844205  46.000000
[[12  5]
 [ 2 27]]
Sensitivity:  0.9310344827586207
Specificity:  0.7058823529411765
Epoch 15/50
----------
Training batch 0/107- batch 0, loss: 1.0894, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1706, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0916, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.2387, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0139, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0105, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0452, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0006, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0221, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.1667, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0273, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 15, train_loss: 0.0012, train_accuracy: 0.9252
class 0: acc 0.8979591836734694, correct 44/49
class 1: acc 0.9482758620689655, correct 55/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.3969, AUC: 0.9026, Accuracy: 0.8478
class 0: acc 0.7647058823529411, correct 13/17
class 1: acc 0.896551724137931, correct 26/29
              precision    recall  f1-score    support
0              0.812500  0.764706  0.787879  17.000000
1              0.866667  0.896552  0.881356  29.000000
accuracy       0.847826  0.847826  0.847826   0.847826
macro avg      0.839583  0.830629  0.834617  46.000000
weighted avg   0.846649  0.847826  0.846810  46.000000
[[13  4]
 [ 3 26]]
Sensitivity:  0.896551724137931
Specificity:  0.7647058823529411
Epoch 16/50
----------
Training batch 0/107- batch 0, loss: 0.4852, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1384, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1421, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.2268, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0276, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0017, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0595, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0002, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0272, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.1016, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0957, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 16, train_loss: 0.0020, train_accuracy: 0.9065
class 0: acc 0.9183673469387755, correct 45/49
class 1: acc 0.896551724137931, correct 52/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4292, AUC: 0.8864, Accuracy: 0.8261
class 0: acc 0.7058823529411765, correct 12/17
class 1: acc 0.896551724137931, correct 26/29
              precision    recall  f1-score    support
0              0.800000  0.705882  0.750000  17.000000
1              0.838710  0.896552  0.866667  29.000000
accuracy       0.826087  0.826087  0.826087   0.826087
macro avg      0.819355  0.801217  0.808333  46.000000
weighted avg   0.824404  0.826087  0.823551  46.000000
[[12  5]
 [ 3 26]]
Sensitivity:  0.896551724137931
Specificity:  0.7058823529411765
Epoch 17/50
----------
Training batch 0/107- batch 0, loss: 0.4216, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1928, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0669, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1323, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0349, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0002, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0556, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0089, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.2954, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0375, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 17, train_loss: 0.0016, train_accuracy: 0.9439
class 0: acc 0.9591836734693877, correct 47/49
class 1: acc 0.9310344827586207, correct 54/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4130, AUC: 0.8966, Accuracy: 0.8261
class 0: acc 0.7058823529411765, correct 12/17
class 1: acc 0.896551724137931, correct 26/29
              precision    recall  f1-score    support
0              0.800000  0.705882  0.750000  17.000000
1              0.838710  0.896552  0.866667  29.000000
accuracy       0.826087  0.826087  0.826087   0.826087
macro avg      0.819355  0.801217  0.808333  46.000000
weighted avg   0.824404  0.826087  0.823551  46.000000
[[12  5]
 [ 3 26]]
Sensitivity:  0.896551724137931
Specificity:  0.7058823529411765
Epoch 18/50
----------
Training batch 0/107- batch 0, loss: 1.7055, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.4698, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0685, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1428, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0171, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0107, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0495, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0070, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.1845, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0241, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 18, train_loss: 0.0007, train_accuracy: 0.9439
class 0: acc 0.9387755102040817, correct 46/49
class 1: acc 0.9482758620689655, correct 55/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5137, AUC: 0.8742, Accuracy: 0.8043
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.7586206896551724, correct 22/29
              precision    recall  f1-score    support
0              0.681818  0.882353  0.769231  17.000000
1              0.916667  0.758621  0.830189  29.000000
accuracy       0.804348  0.804348  0.804348   0.804348
macro avg      0.799242  0.820487  0.799710  46.000000
weighted avg   0.829875  0.804348  0.807661  46.000000
[[15  2]
 [ 7 22]]
Sensitivity:  0.7586206896551724
Specificity:  0.8823529411764706
Epoch 19/50
----------
Training batch 0/107- batch 0, loss: 0.0898, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1074, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0680, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1550, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0232, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0005, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0510, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0033, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.2718, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0368, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 19, train_loss: 0.0008, train_accuracy: 0.9533
class 0: acc 0.9591836734693877, correct 47/49
class 1: acc 0.9482758620689655, correct 55/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5154, AUC: 0.8742, Accuracy: 0.8261
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.7931034482758621, correct 23/29
              precision    recall  f1-score    support
0              0.714286  0.882353  0.789474  17.000000
1              0.920000  0.793103  0.851852  29.000000
accuracy       0.826087  0.826087  0.826087   0.826087
macro avg      0.817143  0.837728  0.820663  46.000000
weighted avg   0.843975  0.826087  0.828799  46.000000
[[15  2]
 [ 6 23]]
Sensitivity:  0.7931034482758621
Specificity:  0.8823529411764706
Epoch 20/50
----------
Training batch 0/107- batch 0, loss: 0.0905, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0895, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0414, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1296, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0296, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0001, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0560, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0008, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.2145, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0365, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 20, train_loss: 0.0011, train_accuracy: 0.9533
class 0: acc 0.9591836734693877, correct 47/49
class 1: acc 0.9482758620689655, correct 55/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4669, AUC: 0.8803, Accuracy: 0.8478
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.8275862068965517, correct 24/29
              precision    recall  f1-score    support
0              0.750000  0.882353  0.810811  17.000000
1              0.923077  0.827586  0.872727  29.000000
accuracy       0.847826  0.847826  0.847826   0.847826
macro avg      0.836538  0.854970  0.841769  46.000000
weighted avg   0.859114  0.847826  0.849845  46.000000
[[15  2]
 [ 5 24]]
Sensitivity:  0.8275862068965517
Specificity:  0.8823529411764706
Epoch 21/50
----------
Training batch 0/107- batch 0, loss: 0.1492, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1462, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0706, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1135, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0215, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0001, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0458, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0014, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0209, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 1.1982, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 21, train_loss: 0.0034, train_accuracy: 0.9065
class 0: acc 0.8775510204081632, correct 43/49
class 1: acc 0.9310344827586207, correct 54/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4761, AUC: 0.8438, Accuracy: 0.7609
class 0: acc 0.6470588235294118, correct 11/17
class 1: acc 0.8275862068965517, correct 24/29
              precision    recall  f1-score   support
0              0.687500  0.647059  0.666667  17.00000
1              0.800000  0.827586  0.813559  29.00000
accuracy       0.760870  0.760870  0.760870   0.76087
macro avg      0.743750  0.737323  0.740113  46.00000
weighted avg   0.758424  0.760870  0.759273  46.00000
[[11  6]
 [ 5 24]]
Sensitivity:  0.8275862068965517
Specificity:  0.6470588235294118
Epoch 22/50
----------
Training batch 0/107- batch 0, loss: 0.5689, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 1.2135, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.4456, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1239, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.1584, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0077, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0922, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0004, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0017, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0535, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.4285, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 22, train_loss: 0.0013, train_accuracy: 0.8785
class 0: acc 0.8571428571428571, correct 42/49
class 1: acc 0.896551724137931, correct 52/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4236, AUC: 0.8844, Accuracy: 0.8043
class 0: acc 0.5882352941176471, correct 10/17
class 1: acc 0.9310344827586207, correct 27/29
              precision    recall  f1-score    support
0              0.833333  0.588235  0.689655  17.000000
1              0.794118  0.931034  0.857143  29.000000
accuracy       0.804348  0.804348  0.804348   0.804348
macro avg      0.813725  0.759635  0.773399  46.000000
weighted avg   0.808610  0.804348  0.795245  46.000000
[[10  7]
 [ 2 27]]
Sensitivity:  0.9310344827586207
Specificity:  0.5882352941176471
Epoch 23/50
----------
Training batch 0/107- batch 0, loss: 0.8233, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 1.2005, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0458, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0956, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0081, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0250, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0114, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0007, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0114, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0756, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0616, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 23, train_loss: 0.0018, train_accuracy: 0.9159
class 0: acc 0.8979591836734694, correct 44/49
class 1: acc 0.9310344827586207, correct 54/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4637, AUC: 0.8945, Accuracy: 0.8043
class 0: acc 0.7058823529411765, correct 12/17
class 1: acc 0.8620689655172413, correct 25/29
              precision    recall  f1-score    support
0              0.750000  0.705882  0.727273  17.000000
1              0.833333  0.862069  0.847458  29.000000
accuracy       0.804348  0.804348  0.804348   0.804348
macro avg      0.791667  0.783976  0.787365  46.000000
weighted avg   0.802536  0.804348  0.803041  46.000000
[[12  5]
 [ 4 25]]
Sensitivity:  0.8620689655172413
Specificity:  0.7058823529411765
Epoch 24/50
----------
Training batch 0/107- batch 0, loss: 0.9421, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1137, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0671, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1077, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0349, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0004, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0265, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0004, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0622, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.2124, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 24, train_loss: 0.0019, train_accuracy: 0.9252
class 0: acc 0.9591836734693877, correct 47/49
class 1: acc 0.896551724137931, correct 52/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5467, AUC: 0.8905, Accuracy: 0.8043
class 0: acc 0.6470588235294118, correct 11/17
class 1: acc 0.896551724137931, correct 26/29
              precision    recall  f1-score    support
0              0.785714  0.647059  0.709677  17.000000
1              0.812500  0.896552  0.852459  29.000000
accuracy       0.804348  0.804348  0.804348   0.804348
macro avg      0.799107  0.771805  0.781068  46.000000
weighted avg   0.802601  0.804348  0.799692  46.000000
[[11  6]
 [ 3 26]]
Sensitivity:  0.896551724137931
Specificity:  0.6470588235294118
Epoch 25/50
----------
Training batch 0/107- batch 0, loss: 0.8704, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 1.1997, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0585, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1216, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0437, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0002, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0648, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0044, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0437, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.1206, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 25, train_loss: 0.0019, train_accuracy: 0.9065
class 0: acc 0.8979591836734694, correct 44/49
class 1: acc 0.9137931034482759, correct 53/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5305, AUC: 0.8824, Accuracy: 0.7826
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.7241379310344828, correct 21/29
              precision    recall  f1-score    support
0              0.652174  0.882353  0.750000  17.000000
1              0.913043  0.724138  0.807692  29.000000
accuracy       0.782609  0.782609  0.782609   0.782609
macro avg      0.782609  0.803245  0.778846  46.000000
weighted avg   0.816635  0.782609  0.786371  46.000000
[[15  2]
 [ 8 21]]
Sensitivity:  0.7241379310344828
Specificity:  0.8823529411764706
Epoch 26/50
----------
Training batch 0/107- batch 0, loss: 0.1105, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1794, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0318, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1025, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0065, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0189, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0005, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.2218, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0632, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 26, train_loss: 0.0025, train_accuracy: 0.9720
class 0: acc 0.9795918367346939, correct 48/49
class 1: acc 0.9655172413793104, correct 56/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4996, AUC: 0.8661, Accuracy: 0.8478
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.8275862068965517, correct 24/29
              precision    recall  f1-score    support
0              0.750000  0.882353  0.810811  17.000000
1              0.923077  0.827586  0.872727  29.000000
accuracy       0.847826  0.847826  0.847826   0.847826
macro avg      0.836538  0.854970  0.841769  46.000000
weighted avg   0.859114  0.847826  0.849845  46.000000
[[15  2]
 [ 5 24]]
Sensitivity:  0.8275862068965517
Specificity:  0.8823529411764706
Epoch 27/50
----------
Training batch 0/107- batch 0, loss: 0.2456, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0982, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0176, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0596, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0098, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0570, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0001, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0025, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0074, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.1306, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 27, train_loss: 0.0026, train_accuracy: 0.9533
class 0: acc 0.9591836734693877, correct 47/49
class 1: acc 0.9482758620689655, correct 55/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5378, AUC: 0.8884, Accuracy: 0.8261
class 0: acc 0.7647058823529411, correct 13/17
class 1: acc 0.8620689655172413, correct 25/29
              precision    recall  f1-score    support
0              0.764706  0.764706  0.764706  17.000000
1              0.862069  0.862069  0.862069  29.000000
accuracy       0.826087  0.826087  0.826087   0.826087
macro avg      0.813387  0.813387  0.813387  46.000000
weighted avg   0.826087  0.826087  0.826087  46.000000
[[13  4]
 [ 4 25]]
Sensitivity:  0.8620689655172413
Specificity:  0.7647058823529411
Epoch 28/50
----------
Training batch 0/107- batch 0, loss: 0.1715, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0726, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0321, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0923, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0174, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0498, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0094, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.5719, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.1452, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 28, train_loss: 0.0015, train_accuracy: 0.9346
class 0: acc 0.9387755102040817, correct 46/49
class 1: acc 0.9310344827586207, correct 54/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5994, AUC: 0.8742, Accuracy: 0.7826
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.7241379310344828, correct 21/29
              precision    recall  f1-score    support
0              0.652174  0.882353  0.750000  17.000000
1              0.913043  0.724138  0.807692  29.000000
accuracy       0.782609  0.782609  0.782609   0.782609
macro avg      0.782609  0.803245  0.778846  46.000000
weighted avg   0.816635  0.782609  0.786371  46.000000
[[15  2]
 [ 8 21]]
Sensitivity:  0.7241379310344828
Specificity:  0.8823529411764706
Epoch 29/50
----------
Training batch 0/107- batch 0, loss: 0.0620, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1329, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0302, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1130, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0121, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0001, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0253, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0015, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0361, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.1326, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 29, train_loss: 0.0015, train_accuracy: 0.9626
class 0: acc 0.9795918367346939, correct 48/49
class 1: acc 0.9482758620689655, correct 55/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4788, AUC: 0.8844, Accuracy: 0.8478
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.8620689655172413, correct 25/29
              precision    recall  f1-score    support
0              0.777778  0.823529  0.800000  17.000000
1              0.892857  0.862069  0.877193  29.000000
accuracy       0.847826  0.847826  0.847826   0.847826
macro avg      0.835317  0.842799  0.838596  46.000000
weighted avg   0.850328  0.847826  0.848665  46.000000
[[14  3]
 [ 4 25]]
Sensitivity:  0.8620689655172413
Specificity:  0.8235294117647058
Epoch 30/50
----------
Training batch 0/107- batch 0, loss: 0.6745, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1791, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0169, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0401, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0100, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0547, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0074, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.1522, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0741, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 30, train_loss: 0.0106, train_accuracy: 0.9533
class 0: acc 0.9591836734693877, correct 47/49
class 1: acc 0.9482758620689655, correct 55/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5892, AUC: 0.8235, Accuracy: 0.7174
class 0: acc 0.7058823529411765, correct 12/17
class 1: acc 0.7241379310344828, correct 21/29
              precision    recall  f1-score    support
0              0.600000  0.705882  0.648649  17.000000
1              0.807692  0.724138  0.763636  29.000000
accuracy       0.717391  0.717391  0.717391   0.717391
macro avg      0.703846  0.715010  0.706143  46.000000
weighted avg   0.730936  0.717391  0.721141  46.000000
[[12  5]
 [ 8 21]]
Sensitivity:  0.7241379310344828
Specificity:  0.7058823529411765
Epoch 31/50
----------
Training batch 0/107- batch 0, loss: 0.0623, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1110, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0356, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1204, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0234, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0457, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0007, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.1313, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0088, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 31, train_loss: 0.0007, train_accuracy: 0.9533
class 0: acc 0.9591836734693877, correct 47/49
class 1: acc 0.9482758620689655, correct 55/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.6621, AUC: 0.8783, Accuracy: 0.7609
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.6896551724137931, correct 20/29
              precision    recall  f1-score   support
0              0.625000  0.882353  0.731707  17.00000
1              0.909091  0.689655  0.784314  29.00000
accuracy       0.760870  0.760870  0.760870   0.76087
macro avg      0.767045  0.786004  0.758011  46.00000
weighted avg   0.804101  0.760870  0.764872  46.00000
[[15  2]
 [ 9 20]]
Sensitivity:  0.6896551724137931
Specificity:  0.8823529411764706
Epoch 32/50
----------
Training batch 0/107- batch 0, loss: 0.0385, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1050, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0351, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0964, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0070, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0001, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0408, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0002, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0583, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0065, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 32, train_loss: 0.0006, train_accuracy: 0.9813
class 0: acc 0.9795918367346939, correct 48/49
class 1: acc 0.9827586206896551, correct 57/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.7591, AUC: 0.8682, Accuracy: 0.7609
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.6896551724137931, correct 20/29
              precision    recall  f1-score   support
0              0.625000  0.882353  0.731707  17.00000
1              0.909091  0.689655  0.784314  29.00000
accuracy       0.760870  0.760870  0.760870   0.76087
macro avg      0.767045  0.786004  0.758011  46.00000
weighted avg   0.804101  0.760870  0.764872  46.00000
[[15  2]
 [ 9 20]]
Sensitivity:  0.6896551724137931
Specificity:  0.8823529411764706
Epoch 33/50
----------
Training batch 0/107- batch 0, loss: 0.0227, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0418, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0369, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0902, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0050, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0001, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0188, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0002, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0833, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 33, train_loss: 0.0028, train_accuracy: 0.9720
class 0: acc 1.0, correct 49/49
class 1: acc 0.9482758620689655, correct 55/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.6094, AUC: 0.8742, Accuracy: 0.8696
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.8620689655172413, correct 25/29
              precision    recall  f1-score    support
0              0.789474  0.882353  0.833333  17.000000
1              0.925926  0.862069  0.892857  29.000000
accuracy       0.869565  0.869565  0.869565   0.869565
macro avg      0.857700  0.872211  0.863095  46.000000
weighted avg   0.875498  0.869565  0.870859  46.000000
[[15  2]
 [ 4 25]]
Sensitivity:  0.8620689655172413
Specificity:  0.8823529411764706
Epoch 34/50
----------
Training batch 0/107- batch 0, loss: 0.6583, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0126, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0061, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0449, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0072, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0325, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0002, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0436, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0617, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 34, train_loss: 0.0014, train_accuracy: 0.9626
class 0: acc 0.9795918367346939, correct 48/49
class 1: acc 0.9482758620689655, correct 55/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5466, AUC: 0.8783, Accuracy: 0.7826
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.7241379310344828, correct 21/29
              precision    recall  f1-score    support
0              0.652174  0.882353  0.750000  17.000000
1              0.913043  0.724138  0.807692  29.000000
accuracy       0.782609  0.782609  0.782609   0.782609
macro avg      0.782609  0.803245  0.778846  46.000000
weighted avg   0.816635  0.782609  0.786371  46.000000
[[15  2]
 [ 8 21]]
Sensitivity:  0.7241379310344828
Specificity:  0.8823529411764706
Epoch 35/50
----------
Training batch 0/107- batch 0, loss: 0.0543, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0996, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0226, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0735, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0052, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0183, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0042, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0962, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 35, train_loss: 0.0023, train_accuracy: 0.9720
class 0: acc 0.9795918367346939, correct 48/49
class 1: acc 0.9655172413793104, correct 56/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4902, AUC: 0.8824, Accuracy: 0.8696
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.896551724137931, correct 26/29
              precision    recall  f1-score    support
0              0.823529  0.823529  0.823529  17.000000
1              0.896552  0.896552  0.896552  29.000000
accuracy       0.869565  0.869565  0.869565   0.869565
macro avg      0.860041  0.860041  0.860041  46.000000
weighted avg   0.869565  0.869565  0.869565  46.000000
[[14  3]
 [ 3 26]]
Sensitivity:  0.896551724137931
Specificity:  0.8235294117647058
Epoch 36/50
----------
Training batch 0/107- batch 0, loss: 0.1493, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0649, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0376, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0618, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0017, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0001, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0478, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0004, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0038, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0161, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 36, train_loss: 0.0008, train_accuracy: 0.9720
class 0: acc 0.9795918367346939, correct 48/49
class 1: acc 0.9655172413793104, correct 56/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5415, AUC: 0.8783, Accuracy: 0.8261
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.8275862068965517, correct 24/29
              precision    recall  f1-score    support
0              0.736842  0.823529  0.777778  17.000000
1              0.888889  0.827586  0.857143  29.000000
accuracy       0.826087  0.826087  0.826087   0.826087
macro avg      0.812865  0.825558  0.817460  46.000000
weighted avg   0.832698  0.826087  0.827812  46.000000
[[14  3]
 [ 5 24]]
Sensitivity:  0.8275862068965517
Specificity:  0.8235294117647058
Epoch 37/50
----------
Training batch 0/107- batch 0, loss: 0.1584, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1096, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0104, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0464, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0016, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0007, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0110, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0007, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0018, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0106, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 37, train_loss: 0.0007, train_accuracy: 0.9907
class 0: acc 1.0, correct 49/49
class 1: acc 0.9827586206896551, correct 57/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.6277, AUC: 0.8763, Accuracy: 0.8261
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.8275862068965517, correct 24/29
              precision    recall  f1-score    support
0              0.736842  0.823529  0.777778  17.000000
1              0.888889  0.827586  0.857143  29.000000
accuracy       0.826087  0.826087  0.826087   0.826087
macro avg      0.812865  0.825558  0.817460  46.000000
weighted avg   0.832698  0.826087  0.827812  46.000000
[[14  3]
 [ 5 24]]
Sensitivity:  0.8275862068965517
Specificity:  0.8235294117647058
Epoch 38/50
----------
Training batch 0/107- batch 0, loss: 2.6850, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0688, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0064, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0137, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0021, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0004, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0109, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0189, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0137, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 38, train_loss: 0.0006, train_accuracy: 0.9720
class 0: acc 0.9591836734693877, correct 47/49
class 1: acc 0.9827586206896551, correct 57/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.7175, AUC: 0.8641, Accuracy: 0.8043
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.7586206896551724, correct 22/29
              precision    recall  f1-score    support
0              0.681818  0.882353  0.769231  17.000000
1              0.916667  0.758621  0.830189  29.000000
accuracy       0.804348  0.804348  0.804348   0.804348
macro avg      0.799242  0.820487  0.799710  46.000000
weighted avg   0.829875  0.804348  0.807661  46.000000
[[15  2]
 [ 7 22]]
Sensitivity:  0.7586206896551724
Specificity:  0.8823529411764706
Epoch 39/50
----------
Training batch 0/107- batch 0, loss: 0.0282, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0306, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0211, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1236, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0097, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0163, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0028, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0222, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 39, train_loss: 0.0008, train_accuracy: 0.9720
class 0: acc 0.9795918367346939, correct 48/49
class 1: acc 0.9655172413793104, correct 56/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.6820, AUC: 0.8600, Accuracy: 0.8043
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.7931034482758621, correct 23/29
              precision    recall  f1-score    support
0              0.700000  0.823529  0.756757  17.000000
1              0.884615  0.793103  0.836364  29.000000
accuracy       0.804348  0.804348  0.804348   0.804348
macro avg      0.792308  0.808316  0.796560  46.000000
weighted avg   0.816388  0.804348  0.806944  46.000000
[[14  3]
 [ 6 23]]
Sensitivity:  0.7931034482758621
Specificity:  0.8235294117647058
Epoch 40/50
----------
Training batch 0/107- batch 0, loss: 0.0260, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0429, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0343, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0436, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0017, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0065, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0034, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0112, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 40, train_loss: 0.0013, train_accuracy: 0.9907
class 0: acc 1.0, correct 49/49
class 1: acc 0.9827586206896551, correct 57/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.6653, AUC: 0.8905, Accuracy: 0.8696
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.896551724137931, correct 26/29
              precision    recall  f1-score    support
0              0.823529  0.823529  0.823529  17.000000
1              0.896552  0.896552  0.896552  29.000000
accuracy       0.869565  0.869565  0.869565   0.869565
macro avg      0.860041  0.860041  0.860041  46.000000
weighted avg   0.869565  0.869565  0.869565  46.000000
[[14  3]
 [ 3 26]]
Sensitivity:  0.896551724137931
Specificity:  0.8235294117647058
Epoch 41/50
----------
Training batch 0/107- batch 0, loss: 1.3173, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0662, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0082, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0339, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0022, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0093, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0013, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.4464, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 41, train_loss: 0.0011, train_accuracy: 0.9439
class 0: acc 0.9387755102040817, correct 46/49
class 1: acc 0.9482758620689655, correct 55/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.7344, AUC: 0.8641, Accuracy: 0.7826
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.7241379310344828, correct 21/29
              precision    recall  f1-score    support
0              0.652174  0.882353  0.750000  17.000000
1              0.913043  0.724138  0.807692  29.000000
accuracy       0.782609  0.782609  0.782609   0.782609
macro avg      0.782609  0.803245  0.778846  46.000000
weighted avg   0.816635  0.782609  0.786371  46.000000
[[15  2]
 [ 8 21]]
Sensitivity:  0.7241379310344828
Specificity:  0.8823529411764706
Epoch 42/50
----------
Training batch 0/107- batch 0, loss: 0.0323, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0301, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0095, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1015, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0028, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0235, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0098, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0100, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 42, train_loss: 0.0007, train_accuracy: 0.9720
class 0: acc 0.9795918367346939, correct 48/49
class 1: acc 0.9655172413793104, correct 56/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.8439, AUC: 0.8540, Accuracy: 0.7609
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.6896551724137931, correct 20/29
              precision    recall  f1-score   support
0              0.625000  0.882353  0.731707  17.00000
1              0.909091  0.689655  0.784314  29.00000
accuracy       0.760870  0.760870  0.760870   0.76087
macro avg      0.767045  0.786004  0.758011  46.00000
weighted avg   0.804101  0.760870  0.764872  46.00000
[[15  2]
 [ 9 20]]
Sensitivity:  0.6896551724137931
Specificity:  0.8823529411764706
Epoch 43/50
----------
Training batch 0/107- batch 0, loss: 0.0243, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0951, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0361, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0624, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0034, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0004, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0130, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0001, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0126, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 43, train_loss: 0.0010, train_accuracy: 0.9907
class 0: acc 1.0, correct 49/49
class 1: acc 0.9827586206896551, correct 57/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.8282, AUC: 0.8702, Accuracy: 0.8043
class 0: acc 0.7647058823529411, correct 13/17
class 1: acc 0.8275862068965517, correct 24/29
              precision    recall  f1-score    support
0              0.722222  0.764706  0.742857  17.000000
1              0.857143  0.827586  0.842105  29.000000
accuracy       0.804348  0.804348  0.804348   0.804348
macro avg      0.789683  0.796146  0.792481  46.000000
weighted avg   0.807281  0.804348  0.805427  46.000000
[[13  4]
 [ 5 24]]
Sensitivity:  0.8275862068965517
Specificity:  0.7647058823529411
Epoch 44/50
----------
Training batch 0/107- batch 0, loss: 0.1470, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0337, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0142, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0429, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0015, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0085, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0000, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0179, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 44, train_loss: 0.0018, train_accuracy: 0.9907
class 0: acc 1.0, correct 49/49
class 1: acc 0.9827586206896551, correct 57/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.8978, AUC: 0.8560, Accuracy: 0.8043
class 0: acc 0.7647058823529411, correct 13/17
class 1: acc 0.8275862068965517, correct 24/29
              precision    recall  f1-score    support
0              0.722222  0.764706  0.742857  17.000000
1              0.857143  0.827586  0.842105  29.000000
accuracy       0.804348  0.804348  0.804348   0.804348
macro avg      0.789683  0.796146  0.792481  46.000000
weighted avg   0.807281  0.804348  0.805427  46.000000
[[13  4]
 [ 5 24]]
Sensitivity:  0.8275862068965517
Specificity:  0.7647058823529411
Epoch 45/50
----------
Training batch 0/107- batch 0, loss: 0.0110, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0213, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0072, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0040, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0017, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0127, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0032, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0468, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 45, train_loss: 0.0008, train_accuracy: 0.9439
class 0: acc 0.9387755102040817, correct 46/49
class 1: acc 0.9482758620689655, correct 55/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5955, AUC: 0.8925, Accuracy: 0.8696
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.896551724137931, correct 26/29
              precision    recall  f1-score    support
0              0.823529  0.823529  0.823529  17.000000
1              0.896552  0.896552  0.896552  29.000000
accuracy       0.869565  0.869565  0.869565   0.869565
macro avg      0.860041  0.860041  0.860041  46.000000
weighted avg   0.869565  0.869565  0.869565  46.000000
[[14  3]
 [ 3 26]]
Sensitivity:  0.896551724137931
Specificity:  0.8235294117647058
Epoch 46/50
----------
Training batch 0/107- batch 0, loss: 0.1258, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0627, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0135, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0394, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0038, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0104, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0004, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0258, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 46, train_loss: 0.0005, train_accuracy: 0.9907
class 0: acc 1.0, correct 49/49
class 1: acc 0.9827586206896551, correct 57/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.6809, AUC: 0.8925, Accuracy: 0.8261
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.8275862068965517, correct 24/29
              precision    recall  f1-score    support
0              0.736842  0.823529  0.777778  17.000000
1              0.888889  0.827586  0.857143  29.000000
accuracy       0.826087  0.826087  0.826087   0.826087
macro avg      0.812865  0.825558  0.817460  46.000000
weighted avg   0.832698  0.826087  0.827812  46.000000
[[14  3]
 [ 5 24]]
Sensitivity:  0.8275862068965517
Specificity:  0.8235294117647058
Epoch 47/50
----------
Training batch 0/107- batch 0, loss: 0.3184, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0202, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0056, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0473, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0013, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0097, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0007, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0336, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 47, train_loss: 0.0007, train_accuracy: 0.9907
class 0: acc 1.0, correct 49/49
class 1: acc 0.9827586206896551, correct 57/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.7428, AUC: 0.8864, Accuracy: 0.8478
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.8620689655172413, correct 25/29
              precision    recall  f1-score    support
0              0.777778  0.823529  0.800000  17.000000
1              0.892857  0.862069  0.877193  29.000000
accuracy       0.847826  0.847826  0.847826   0.847826
macro avg      0.835317  0.842799  0.838596  46.000000
weighted avg   0.850328  0.847826  0.848665  46.000000
[[14  3]
 [ 4 25]]
Sensitivity:  0.8620689655172413
Specificity:  0.8235294117647058
Epoch 48/50
----------
Training batch 0/107- batch 0, loss: 0.0092, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0169, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0108, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0153, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0006, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0000, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0011, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0001, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0111, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 48, train_loss: 0.0013, train_accuracy: 0.9907
class 0: acc 1.0, correct 49/49
class 1: acc 0.9827586206896551, correct 57/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.8321, AUC: 0.8864, Accuracy: 0.8478
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.8620689655172413, correct 25/29
              precision    recall  f1-score    support
0              0.777778  0.823529  0.800000  17.000000
1              0.892857  0.862069  0.877193  29.000000
accuracy       0.847826  0.847826  0.847826   0.847826
macro avg      0.835317  0.842799  0.838596  46.000000
weighted avg   0.850328  0.847826  0.848665  46.000000
[[14  3]
 [ 4 25]]
Sensitivity:  0.8620689655172413
Specificity:  0.8235294117647058
Epoch 49/50
----------
Training batch 0/107- batch 0, loss: 3.9252, label: 0, bag_size: 263
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0217, label: 0, bag_size: 149
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0051, label: 0, bag_size: 84
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0044, label: 0, bag_size: 571
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0001, label: 0, bag_size: 26
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0003, label: 1, bag_size: 138
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0010, label: 0, bag_size: 151
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 455
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0000, label: 1, bag_size: 513
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0033, label: 1, bag_size: 233
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0341, label: 0, bag_size: 124
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 49, train_loss: 0.0007, train_accuracy: 0.9439
class 0: acc 0.9387755102040817, correct 46/49
class 1: acc 0.9482758620689655, correct 55/58
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.9130, AUC: 0.9026, Accuracy: 0.7826
class 0: acc 0.5294117647058824, correct 9/17
class 1: acc 0.9310344827586207, correct 27/29
              precision    recall  f1-score    support
0              0.818182  0.529412  0.642857  17.000000
1              0.771429  0.931034  0.843750  29.000000
accuracy       0.782609  0.782609  0.782609   0.782609
macro avg      0.794805  0.730223  0.743304  46.000000
weighted avg   0.788707  0.782609  0.769507  46.000000
[[ 9  8]
 [ 2 27]]
Sensitivity:  0.9310344827586207
Specificity:  0.5294117647058824

Training completed in 590m 52s
CD68
Epoch 0/50
----------
Training batch 0/107- batch 0, loss: 0.7041, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.6778, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.6913, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.6849, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.6976, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.6633, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.7046, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.6953, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.6756, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.6290, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.8679, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 0, train_loss: 0.0086, train_accuracy: 0.4762
class 0: acc 0.3333333333333333, correct 16/48
class 1: acc 0.5964912280701754, correct 34/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.6495, AUC: 0.7353, Accuracy: 0.6222
class 0: acc 0.0, correct 0/17
class 1: acc 1.0, correct 28/28
              precision    recall  f1-score    support
0              1.000000  0.000000  0.000000  17.000000
1              0.622222  1.000000  0.767123  28.000000
accuracy       0.622222  0.622222  0.622222   0.622222
macro avg      0.811111  0.500000  0.383562  45.000000
weighted avg   0.764938  0.622222  0.477321  45.000000
[[ 0 17]
 [ 0 28]]
Sensitivity:  1.0
Specificity:  0.0
Epoch 1/50
----------
Training batch 0/107- batch 0, loss: 0.9135, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.7169, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.8421, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.7598, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 1.0785, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.5851, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.6702, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.6948, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.6328, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.5841, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.7834, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 1, train_loss: 0.0081, train_accuracy: 0.4762
class 0: acc 0.041666666666666664, correct 2/48
class 1: acc 0.8421052631578947, correct 48/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.6162, AUC: 0.8277, Accuracy: 0.6222
class 0: acc 0.0, correct 0/17
class 1: acc 1.0, correct 28/28
              precision    recall  f1-score    support
0              1.000000  0.000000  0.000000  17.000000
1              0.622222  1.000000  0.767123  28.000000
accuracy       0.622222  0.622222  0.622222   0.622222
macro avg      0.811111  0.500000  0.383562  45.000000
weighted avg   0.764938  0.622222  0.477321  45.000000
[[ 0 17]
 [ 0 28]]
Sensitivity:  1.0
Specificity:  0.0
Epoch 2/50
----------
Training batch 0/107- batch 0, loss: 0.9448, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.7223, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.8718, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.7995, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 1.2133, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.7403, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.6225, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.1645, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.3882, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.1105, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.8645, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 2, train_loss: 0.0080, train_accuracy: 0.6571
class 0: acc 0.4583333333333333, correct 22/48
class 1: acc 0.8245614035087719, correct 47/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5086, AUC: 0.8445, Accuracy: 0.8444
class 0: acc 0.7647058823529411, correct 13/17
class 1: acc 0.8928571428571429, correct 25/28
              precision    recall  f1-score    support
0              0.812500  0.764706  0.787879  17.000000
1              0.862069  0.892857  0.877193  28.000000
accuracy       0.844444  0.844444  0.844444   0.844444
macro avg      0.837284  0.828782  0.832536  45.000000
weighted avg   0.843343  0.844444  0.843452  45.000000
[[13  4]
 [ 3 25]]
Sensitivity:  0.8928571428571429
Specificity:  0.7647058823529411
Epoch 3/50
----------
Training batch 0/107- batch 0, loss: 1.5331, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.5557, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.5375, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.5229, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.7092, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.6269, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.3585, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.5372, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.4321, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0480, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.6559, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 3, train_loss: 0.0095, train_accuracy: 0.7048
class 0: acc 0.7916666666666666, correct 38/48
class 1: acc 0.631578947368421, correct 36/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5208, AUC: 0.8361, Accuracy: 0.8444
class 0: acc 0.7647058823529411, correct 13/17
class 1: acc 0.8928571428571429, correct 25/28
              precision    recall  f1-score    support
0              0.812500  0.764706  0.787879  17.000000
1              0.862069  0.892857  0.877193  28.000000
accuracy       0.844444  0.844444  0.844444   0.844444
macro avg      0.837284  0.828782  0.832536  45.000000
weighted avg   0.843343  0.844444  0.843452  45.000000
[[13  4]
 [ 3 25]]
Sensitivity:  0.8928571428571429
Specificity:  0.7647058823529411
Epoch 4/50
----------
Training batch 0/107- batch 0, loss: 1.5264, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.5773, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.7885, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.5754, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.5227, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.5397, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.4330, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0088, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.1061, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0192, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.7515, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 4, train_loss: 0.0047, train_accuracy: 0.7810
class 0: acc 0.7708333333333334, correct 37/48
class 1: acc 0.7894736842105263, correct 45/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5081, AUC: 0.8550, Accuracy: 0.7556
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.7142857142857143, correct 20/28
              precision    recall  f1-score    support
0              0.636364  0.823529  0.717949  17.000000
1              0.869565  0.714286  0.784314  28.000000
accuracy       0.755556  0.755556  0.755556   0.755556
macro avg      0.752964  0.768908  0.751131  45.000000
weighted avg   0.781467  0.755556  0.759243  45.000000
[[14  3]
 [ 8 20]]
Sensitivity:  0.7142857142857143
Specificity:  0.8235294117647058
Epoch 5/50
----------
Training batch 0/107- batch 0, loss: 1.2515, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.3896, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.4176, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.3794, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.2819, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.8036, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.2936, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0051, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0489, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0179, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.2660, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 5, train_loss: 0.0022, train_accuracy: 0.8190
class 0: acc 0.8333333333333334, correct 40/48
class 1: acc 0.8070175438596491, correct 46/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4480, AUC: 0.8845, Accuracy: 0.8444
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.8214285714285714, correct 23/28
              precision    recall  f1-score    support
0              0.750000  0.882353  0.810811  17.000000
1              0.920000  0.821429  0.867925  28.000000
accuracy       0.844444  0.844444  0.844444   0.844444
macro avg      0.835000  0.851891  0.839368  45.000000
weighted avg   0.855778  0.844444  0.846348  45.000000
[[15  2]
 [ 5 23]]
Sensitivity:  0.8214285714285714
Specificity:  0.8823529411764706
Epoch 6/50
----------
Training batch 0/107- batch 0, loss: 1.6390, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.2267, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.5318, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.5642, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.3039, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 1.0329, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.1831, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0047, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0332, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0144, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.2443, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 6, train_loss: 0.0016, train_accuracy: 0.8190
class 0: acc 0.8541666666666666, correct 41/48
class 1: acc 0.7894736842105263, correct 45/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4719, AUC: 0.8908, Accuracy: 0.7556
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.6785714285714286, correct 19/28
              precision    recall  f1-score    support
0              0.625000  0.882353  0.731707  17.000000
1              0.904762  0.678571  0.775510  28.000000
accuracy       0.755556  0.755556  0.755556   0.755556
macro avg      0.764881  0.780462  0.753609  45.000000
weighted avg   0.799074  0.755556  0.758962  45.000000
[[15  2]
 [ 9 19]]
Sensitivity:  0.6785714285714286
Specificity:  0.8823529411764706
Epoch 7/50
----------
Training batch 0/107- batch 0, loss: 1.4937, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1810, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.2032, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.2786, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.2418, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.2055, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.2303, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0035, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0467, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0165, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.2772, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 7, train_loss: 0.0023, train_accuracy: 0.8095
class 0: acc 0.8333333333333334, correct 40/48
class 1: acc 0.7894736842105263, correct 45/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4275, AUC: 0.8887, Accuracy: 0.8444
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.8214285714285714, correct 23/28
              precision    recall  f1-score    support
0              0.750000  0.882353  0.810811  17.000000
1              0.920000  0.821429  0.867925  28.000000
accuracy       0.844444  0.844444  0.844444   0.844444
macro avg      0.835000  0.851891  0.839368  45.000000
weighted avg   0.855778  0.844444  0.846348  45.000000
[[15  2]
 [ 5 23]]
Sensitivity:  0.8214285714285714
Specificity:  0.8823529411764706
Epoch 8/50
----------
Training batch 0/107- batch 0, loss: 1.6544, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1718, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.2411, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.2285, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.1777, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.2386, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.3486, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0056, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0812, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0378, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.1927, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 8, train_loss: 0.0017, train_accuracy: 0.8667
class 0: acc 0.8958333333333334, correct 43/48
class 1: acc 0.8421052631578947, correct 48/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4590, AUC: 0.8824, Accuracy: 0.8000
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.75, correct 21/28
              precision    recall  f1-score  support
0              0.681818  0.882353  0.769231     17.0
1              0.913043  0.750000  0.823529     28.0
accuracy       0.800000  0.800000  0.800000      0.8
macro avg      0.797431  0.816176  0.796380     45.0
weighted avg   0.825692  0.800000  0.803017     45.0
[[15  2]
 [ 7 21]]
Sensitivity:  0.75
Specificity:  0.8823529411764706
Epoch 9/50
----------
Training batch 0/107- batch 0, loss: 1.5393, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1797, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.2027, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.2011, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.1249, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1370, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0893, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0030, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0634, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0104, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.1594, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 9, train_loss: 0.0035, train_accuracy: 0.9048
class 0: acc 0.9166666666666666, correct 44/48
class 1: acc 0.8947368421052632, correct 51/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4591, AUC: 0.8697, Accuracy: 0.7778
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.75, correct 21/28
              precision    recall  f1-score    support
0              0.666667  0.823529  0.736842  17.000000
1              0.875000  0.750000  0.807692  28.000000
accuracy       0.777778  0.777778  0.777778   0.777778
macro avg      0.770833  0.786765  0.772267  45.000000
weighted avg   0.796296  0.777778  0.780927  45.000000
[[14  3]
 [ 7 21]]
Sensitivity:  0.75
Specificity:  0.8235294117647058
Epoch 10/50
----------
Training batch 0/107- batch 0, loss: 2.1962, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1011, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1502, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1998, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.1615, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1061, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.1394, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0134, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0972, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0331, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0879, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 10, train_loss: 0.0012, train_accuracy: 0.8762
class 0: acc 0.875, correct 42/48
class 1: acc 0.8771929824561403, correct 50/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4747, AUC: 0.8761, Accuracy: 0.7778
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.75, correct 21/28
              precision    recall  f1-score    support
0              0.666667  0.823529  0.736842  17.000000
1              0.875000  0.750000  0.807692  28.000000
accuracy       0.777778  0.777778  0.777778   0.777778
macro avg      0.770833  0.786765  0.772267  45.000000
weighted avg   0.796296  0.777778  0.780927  45.000000
[[14  3]
 [ 7 21]]
Sensitivity:  0.75
Specificity:  0.8235294117647058
Epoch 11/50
----------
Training batch 0/107- batch 0, loss: 1.8924, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1179, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.7977, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1721, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0847, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.3914, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0880, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0037, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0262, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0103, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.2029, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 11, train_loss: 0.0018, train_accuracy: 0.8381
class 0: acc 0.8125, correct 39/48
class 1: acc 0.8596491228070176, correct 49/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4293, AUC: 0.8718, Accuracy: 0.8667
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.8928571428571429, correct 25/28
              precision    recall  f1-score    support
0              0.823529  0.823529  0.823529  17.000000
1              0.892857  0.892857  0.892857  28.000000
accuracy       0.866667  0.866667  0.866667   0.866667
macro avg      0.858193  0.858193  0.858193  45.000000
weighted avg   0.866667  0.866667  0.866667  45.000000
[[14  3]
 [ 3 25]]
Sensitivity:  0.8928571428571429
Specificity:  0.8235294117647058
Epoch 12/50
----------
Training batch 0/107- batch 0, loss: 1.3005, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.1121, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.2132, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.4280, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0868, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.2145, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0760, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0069, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0462, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0095, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0919, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 12, train_loss: 0.0011, train_accuracy: 0.8667
class 0: acc 0.875, correct 42/48
class 1: acc 0.8596491228070176, correct 49/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4369, AUC: 0.8739, Accuracy: 0.8444
class 0: acc 0.7647058823529411, correct 13/17
class 1: acc 0.8928571428571429, correct 25/28
              precision    recall  f1-score    support
0              0.812500  0.764706  0.787879  17.000000
1              0.862069  0.892857  0.877193  28.000000
accuracy       0.844444  0.844444  0.844444   0.844444
macro avg      0.837284  0.828782  0.832536  45.000000
weighted avg   0.843343  0.844444  0.843452  45.000000
[[13  4]
 [ 3 25]]
Sensitivity:  0.8928571428571429
Specificity:  0.7647058823529411
Epoch 13/50
----------
Training batch 0/107- batch 0, loss: 2.0656, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0765, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1264, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0914, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0644, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1763, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.5886, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0060, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0513, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0201, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0632, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 13, train_loss: 0.0007, train_accuracy: 0.9333
class 0: acc 0.9375, correct 45/48
class 1: acc 0.9298245614035088, correct 53/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4618, AUC: 0.8718, Accuracy: 0.8444
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.8571428571428571, correct 24/28
              precision    recall  f1-score    support
0              0.777778  0.823529  0.800000  17.000000
1              0.888889  0.857143  0.872727  28.000000
accuracy       0.844444  0.844444  0.844444   0.844444
macro avg      0.833333  0.840336  0.836364  45.000000
weighted avg   0.846914  0.844444  0.845253  45.000000
[[14  3]
 [ 4 24]]
Sensitivity:  0.8571428571428571
Specificity:  0.8235294117647058
Epoch 14/50
----------
Training batch 0/107- batch 0, loss: 2.0069, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0742, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.2174, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1455, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.1108, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1499, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.1442, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0064, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0469, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0173, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.1040, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 14, train_loss: 0.0010, train_accuracy: 0.8857
class 0: acc 0.875, correct 42/48
class 1: acc 0.8947368421052632, correct 51/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.3909, AUC: 0.8971, Accuracy: 0.8444
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.8571428571428571, correct 24/28
              precision    recall  f1-score    support
0              0.777778  0.823529  0.800000  17.000000
1              0.888889  0.857143  0.872727  28.000000
accuracy       0.844444  0.844444  0.844444   0.844444
macro avg      0.833333  0.840336  0.836364  45.000000
weighted avg   0.846914  0.844444  0.845253  45.000000
[[14  3]
 [ 4 24]]
Sensitivity:  0.8571428571428571
Specificity:  0.8235294117647058
Epoch 15/50
----------
Training batch 0/107- batch 0, loss: 2.4508, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0860, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.3253, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1114, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0392, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.3889, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0688, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0030, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0926, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0227, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.1794, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 15, train_loss: 0.0144, train_accuracy: 0.9143
class 0: acc 0.8958333333333334, correct 43/48
class 1: acc 0.9298245614035088, correct 53/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5143, AUC: 0.8487, Accuracy: 0.7778
class 0: acc 0.6470588235294118, correct 11/17
class 1: acc 0.8571428571428571, correct 24/28
              precision    recall  f1-score    support
0              0.733333  0.647059  0.687500  17.000000
1              0.800000  0.857143  0.827586  28.000000
accuracy       0.777778  0.777778  0.777778   0.777778
macro avg      0.766667  0.752101  0.757543  45.000000
weighted avg   0.774815  0.777778  0.774665  45.000000
[[11  6]
 [ 4 24]]
Sensitivity:  0.8571428571428571
Specificity:  0.6470588235294118
Epoch 16/50
----------
Training batch 0/107- batch 0, loss: 2.8907, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0571, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.8308, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.2585, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0285, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1922, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0438, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0077, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0875, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0348, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0417, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 16, train_loss: 0.0010, train_accuracy: 0.8381
class 0: acc 0.7708333333333334, correct 37/48
class 1: acc 0.8947368421052632, correct 51/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4383, AUC: 0.8845, Accuracy: 0.8667
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.8571428571428571, correct 24/28
              precision    recall  f1-score    support
0              0.789474  0.882353  0.833333  17.000000
1              0.923077  0.857143  0.888889  28.000000
accuracy       0.866667  0.866667  0.866667   0.866667
macro avg      0.856275  0.869748  0.861111  45.000000
weighted avg   0.872605  0.866667  0.867901  45.000000
[[15  2]
 [ 4 24]]
Sensitivity:  0.8571428571428571
Specificity:  0.8823529411764706
Epoch 17/50
----------
Training batch 0/107- batch 0, loss: 1.6835, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0547, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.2838, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0498, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0185, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1035, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0566, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0010, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0718, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0523, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0418, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 17, train_loss: 0.0007, train_accuracy: 0.8857
class 0: acc 0.875, correct 42/48
class 1: acc 0.8947368421052632, correct 51/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4537, AUC: 0.9097, Accuracy: 0.7778
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.7142857142857143, correct 20/28
              precision    recall  f1-score    support
0              0.652174  0.882353  0.750000  17.000000
1              0.909091  0.714286  0.800000  28.000000
accuracy       0.777778  0.777778  0.777778   0.777778
macro avg      0.780632  0.798319  0.775000  45.000000
weighted avg   0.812033  0.777778  0.781111  45.000000
[[15  2]
 [ 8 20]]
Sensitivity:  0.7142857142857143
Specificity:  0.8823529411764706
Epoch 18/50
----------
Training batch 0/107- batch 0, loss: 1.0282, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0750, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.6971, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.2583, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0084, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1031, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0339, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0025, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.1235, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0322, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0342, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 18, train_loss: 0.0010, train_accuracy: 0.9143
class 0: acc 0.9166666666666666, correct 44/48
class 1: acc 0.9122807017543859, correct 52/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4980, AUC: 0.8887, Accuracy: 0.8000
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.75, correct 21/28
              precision    recall  f1-score  support
0              0.681818  0.882353  0.769231     17.0
1              0.913043  0.750000  0.823529     28.0
accuracy       0.800000  0.800000  0.800000      0.8
macro avg      0.797431  0.816176  0.796380     45.0
weighted avg   0.825692  0.800000  0.803017     45.0
[[15  2]
 [ 7 21]]
Sensitivity:  0.75
Specificity:  0.8823529411764706
Epoch 19/50
----------
Training batch 0/107- batch 0, loss: 1.9670, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0729, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1586, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1498, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0477, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0343, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0483, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0036, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.1235, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0210, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0651, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 19, train_loss: 0.0009, train_accuracy: 0.9048
class 0: acc 0.9166666666666666, correct 44/48
class 1: acc 0.8947368421052632, correct 51/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4138, AUC: 0.8866, Accuracy: 0.8444
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.8571428571428571, correct 24/28
              precision    recall  f1-score    support
0              0.777778  0.823529  0.800000  17.000000
1              0.888889  0.857143  0.872727  28.000000
accuracy       0.844444  0.844444  0.844444   0.844444
macro avg      0.833333  0.840336  0.836364  45.000000
weighted avg   0.846914  0.844444  0.845253  45.000000
[[14  3]
 [ 4 24]]
Sensitivity:  0.8571428571428571
Specificity:  0.8235294117647058
Epoch 20/50
----------
Training batch 0/107- batch 0, loss: 1.8162, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0675, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1376, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1024, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0434, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1846, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0366, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0020, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0678, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0214, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0394, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 20, train_loss: 0.0006, train_accuracy: 0.9048
class 0: acc 0.875, correct 42/48
class 1: acc 0.9298245614035088, correct 53/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5558, AUC: 0.8992, Accuracy: 0.7333
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.6428571428571429, correct 18/28
              precision    recall  f1-score    support
0              0.600000  0.882353  0.714286  17.000000
1              0.900000  0.642857  0.750000  28.000000
accuracy       0.733333  0.733333  0.733333   0.733333
macro avg      0.750000  0.762605  0.732143  45.000000
weighted avg   0.786667  0.733333  0.736508  45.000000
[[15  2]
 [10 18]]
Sensitivity:  0.6428571428571429
Specificity:  0.8823529411764706
Epoch 21/50
----------
Training batch 0/107- batch 0, loss: 1.1338, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0364, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0940, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.2294, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0535, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0553, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0656, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0021, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0120, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0156, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0318, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 21, train_loss: 0.0008, train_accuracy: 0.8762
class 0: acc 0.875, correct 42/48
class 1: acc 0.8771929824561403, correct 50/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5612, AUC: 0.8803, Accuracy: 0.7333
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.6428571428571429, correct 18/28
              precision    recall  f1-score    support
0              0.600000  0.882353  0.714286  17.000000
1              0.900000  0.642857  0.750000  28.000000
accuracy       0.733333  0.733333  0.733333   0.733333
macro avg      0.750000  0.762605  0.732143  45.000000
weighted avg   0.786667  0.733333  0.736508  45.000000
[[15  2]
 [10 18]]
Sensitivity:  0.6428571428571429
Specificity:  0.8823529411764706
Epoch 22/50
----------
Training batch 0/107- batch 0, loss: 1.6866, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0696, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1585, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0850, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0156, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1171, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.1823, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0004, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0591, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0452, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0532, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 22, train_loss: 0.0009, train_accuracy: 0.9048
class 0: acc 0.8958333333333334, correct 43/48
class 1: acc 0.9122807017543859, correct 52/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4598, AUC: 0.9076, Accuracy: 0.7778
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.7142857142857143, correct 20/28
              precision    recall  f1-score    support
0              0.652174  0.882353  0.750000  17.000000
1              0.909091  0.714286  0.800000  28.000000
accuracy       0.777778  0.777778  0.777778   0.777778
macro avg      0.780632  0.798319  0.775000  45.000000
weighted avg   0.812033  0.777778  0.781111  45.000000
[[15  2]
 [ 8 20]]
Sensitivity:  0.7142857142857143
Specificity:  0.8823529411764706
Epoch 23/50
----------
Training batch 0/107- batch 0, loss: 1.5339, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0961, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.2046, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.5230, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0827, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.2157, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0681, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0021, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0129, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0234, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0520, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 23, train_loss: 0.0015, train_accuracy: 0.8857
class 0: acc 0.875, correct 42/48
class 1: acc 0.8947368421052632, correct 51/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.3886, AUC: 0.9202, Accuracy: 0.8667
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.8571428571428571, correct 24/28
              precision    recall  f1-score    support
0              0.789474  0.882353  0.833333  17.000000
1              0.923077  0.857143  0.888889  28.000000
accuracy       0.866667  0.866667  0.866667   0.866667
macro avg      0.856275  0.869748  0.861111  45.000000
weighted avg   0.872605  0.866667  0.867901  45.000000
[[15  2]
 [ 4 24]]
Sensitivity:  0.8571428571428571
Specificity:  0.8823529411764706
Epoch 24/50
----------
Training batch 0/107- batch 0, loss: 1.4248, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0900, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1398, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0996, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0056, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1477, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0718, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0013, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0510, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0067, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0600, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 24, train_loss: 0.0026, train_accuracy: 0.9238
class 0: acc 0.8958333333333334, correct 43/48
class 1: acc 0.9473684210526315, correct 54/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4371, AUC: 0.8908, Accuracy: 0.8444
class 0: acc 0.7647058823529411, correct 13/17
class 1: acc 0.8928571428571429, correct 25/28
              precision    recall  f1-score    support
0              0.812500  0.764706  0.787879  17.000000
1              0.862069  0.892857  0.877193  28.000000
accuracy       0.844444  0.844444  0.844444   0.844444
macro avg      0.837284  0.828782  0.832536  45.000000
weighted avg   0.843343  0.844444  0.843452  45.000000
[[13  4]
 [ 3 25]]
Sensitivity:  0.8928571428571429
Specificity:  0.7647058823529411
Epoch 25/50
----------
Training batch 0/107- batch 0, loss: 2.5162, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0422, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.2166, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0569, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0021, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1628, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0324, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0043, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0197, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0246, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.9972, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 25, train_loss: 0.0096, train_accuracy: 0.8476
class 0: acc 0.7291666666666666, correct 35/48
class 1: acc 0.9473684210526315, correct 54/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4461, AUC: 0.8845, Accuracy: 0.8222
class 0: acc 0.6470588235294118, correct 11/17
class 1: acc 0.9285714285714286, correct 26/28
              precision    recall  f1-score    support
0              0.846154  0.647059  0.733333  17.000000
1              0.812500  0.928571  0.866667  28.000000
accuracy       0.822222  0.822222  0.822222   0.822222
macro avg      0.829327  0.787815  0.800000  45.000000
weighted avg   0.825214  0.822222  0.816296  45.000000
[[11  6]
 [ 2 26]]
Sensitivity:  0.9285714285714286
Specificity:  0.6470588235294118
Epoch 26/50
----------
Training batch 0/107- batch 0, loss: 1.6766, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0807, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1180, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1465, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0339, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.2543, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0471, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0052, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0236, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0299, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0462, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 26, train_loss: 0.0005, train_accuracy: 0.9048
class 0: acc 0.875, correct 42/48
class 1: acc 0.9298245614035088, correct 53/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4932, AUC: 0.8929, Accuracy: 0.7778
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.7142857142857143, correct 20/28
              precision    recall  f1-score    support
0              0.652174  0.882353  0.750000  17.000000
1              0.909091  0.714286  0.800000  28.000000
accuracy       0.777778  0.777778  0.777778   0.777778
macro avg      0.780632  0.798319  0.775000  45.000000
weighted avg   0.812033  0.777778  0.781111  45.000000
[[15  2]
 [ 8 20]]
Sensitivity:  0.7142857142857143
Specificity:  0.8823529411764706
Epoch 27/50
----------
Training batch 0/107- batch 0, loss: 1.4469, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0213, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0843, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0473, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0056, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0637, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0211, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0012, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0122, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0105, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0256, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 27, train_loss: 0.0005, train_accuracy: 0.9429
class 0: acc 0.8958333333333334, correct 43/48
class 1: acc 0.9824561403508771, correct 56/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.3775, AUC: 0.8887, Accuracy: 0.8444
class 0: acc 0.7647058823529411, correct 13/17
class 1: acc 0.8928571428571429, correct 25/28
              precision    recall  f1-score    support
0              0.812500  0.764706  0.787879  17.000000
1              0.862069  0.892857  0.877193  28.000000
accuracy       0.844444  0.844444  0.844444   0.844444
macro avg      0.837284  0.828782  0.832536  45.000000
weighted avg   0.843343  0.844444  0.843452  45.000000
[[13  4]
 [ 3 25]]
Sensitivity:  0.8928571428571429
Specificity:  0.7647058823529411
Epoch 28/50
----------
Training batch 0/107- batch 0, loss: 2.5243, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0214, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0704, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0133, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0016, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1620, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.3947, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0010, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0167, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0097, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0167, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 28, train_loss: 0.0002, train_accuracy: 0.9429
class 0: acc 0.9166666666666666, correct 44/48
class 1: acc 0.9649122807017544, correct 55/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5189, AUC: 0.8929, Accuracy: 0.8222
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.7857142857142857, correct 22/28
              precision    recall  f1-score    support
0              0.714286  0.882353  0.789474  17.000000
1              0.916667  0.785714  0.846154  28.000000
accuracy       0.822222  0.822222  0.822222   0.822222
macro avg      0.815476  0.834034  0.817814  45.000000
weighted avg   0.840212  0.822222  0.824741  45.000000
[[15  2]
 [ 6 22]]
Sensitivity:  0.7857142857142857
Specificity:  0.8823529411764706
Epoch 29/50
----------
Training batch 0/107- batch 0, loss: 2.0723, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0215, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0379, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0610, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0056, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1338, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0095, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0024, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0268, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.1030, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0131, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 29, train_loss: 0.0008, train_accuracy: 0.9143
class 0: acc 0.9166666666666666, correct 44/48
class 1: acc 0.9122807017543859, correct 52/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4694, AUC: 0.9223, Accuracy: 0.8000
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.75, correct 21/28
              precision    recall  f1-score  support
0              0.681818  0.882353  0.769231     17.0
1              0.913043  0.750000  0.823529     28.0
accuracy       0.800000  0.800000  0.800000      0.8
macro avg      0.797431  0.816176  0.796380     45.0
weighted avg   0.825692  0.800000  0.803017     45.0
[[15  2]
 [ 7 21]]
Sensitivity:  0.75
Specificity:  0.8823529411764706
Epoch 30/50
----------
Training batch 0/107- batch 0, loss: 2.0493, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0185, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0457, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0756, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0046, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0419, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0097, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0010, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0071, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0270, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0050, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 30, train_loss: 0.0005, train_accuracy: 0.9333
class 0: acc 0.9166666666666666, correct 44/48
class 1: acc 0.9473684210526315, correct 54/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.7702, AUC: 0.8824, Accuracy: 0.7111
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.6071428571428571, correct 17/28
              precision    recall  f1-score    support
0              0.576923  0.882353  0.697674  17.000000
1              0.894737  0.607143  0.723404  28.000000
accuracy       0.711111  0.711111  0.711111   0.711111
macro avg      0.735830  0.744748  0.710539  45.000000
weighted avg   0.774674  0.711111  0.713684  45.000000
[[15  2]
 [11 17]]
Sensitivity:  0.6071428571428571
Specificity:  0.8823529411764706
Epoch 31/50
----------
Training batch 0/107- batch 0, loss: 0.3418, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0625, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0644, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0535, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0094, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.1240, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0094, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0005, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0253, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0180, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0317, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 31, train_loss: 0.0008, train_accuracy: 0.9333
class 0: acc 0.8958333333333334, correct 43/48
class 1: acc 0.9649122807017544, correct 55/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5053, AUC: 0.8971, Accuracy: 0.8000
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.75, correct 21/28
              precision    recall  f1-score  support
0              0.681818  0.882353  0.769231     17.0
1              0.913043  0.750000  0.823529     28.0
accuracy       0.800000  0.800000  0.800000      0.8
macro avg      0.797431  0.816176  0.796380     45.0
weighted avg   0.825692  0.800000  0.803017     45.0
[[15  2]
 [ 7 21]]
Sensitivity:  0.75
Specificity:  0.8823529411764706
Epoch 32/50
----------
Training batch 0/107- batch 0, loss: 1.8061, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0138, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.4779, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0588, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0315, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0915, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0173, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0014, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0017, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0130, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0177, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 32, train_loss: 0.0007, train_accuracy: 0.9048
class 0: acc 0.8958333333333334, correct 43/48
class 1: acc 0.9122807017543859, correct 52/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5430, AUC: 0.8824, Accuracy: 0.8000
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.75, correct 21/28
              precision    recall  f1-score  support
0              0.681818  0.882353  0.769231     17.0
1              0.913043  0.750000  0.823529     28.0
accuracy       0.800000  0.800000  0.800000      0.8
macro avg      0.797431  0.816176  0.796380     45.0
weighted avg   0.825692  0.800000  0.803017     45.0
[[15  2]
 [ 7 21]]
Sensitivity:  0.75
Specificity:  0.8823529411764706
Epoch 33/50
----------
Training batch 0/107- batch 0, loss: 1.6327, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0506, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1133, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0635, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0113, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0544, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0235, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0003, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.1249, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0441, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0259, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 33, train_loss: 0.0004, train_accuracy: 0.9429
class 0: acc 0.9375, correct 45/48
class 1: acc 0.9473684210526315, correct 54/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5681, AUC: 0.8866, Accuracy: 0.7778
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.7142857142857143, correct 20/28
              precision    recall  f1-score    support
0              0.652174  0.882353  0.750000  17.000000
1              0.909091  0.714286  0.800000  28.000000
accuracy       0.777778  0.777778  0.777778   0.777778
macro avg      0.780632  0.798319  0.775000  45.000000
weighted avg   0.812033  0.777778  0.781111  45.000000
[[15  2]
 [ 8 20]]
Sensitivity:  0.7142857142857143
Specificity:  0.8823529411764706
Epoch 34/50
----------
Training batch 0/107- batch 0, loss: 1.7142, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0399, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1129, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1412, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0204, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0170, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0415, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0013, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0248, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0209, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 34, train_loss: 0.0012, train_accuracy: 0.9048
class 0: acc 0.8541666666666666, correct 41/48
class 1: acc 0.9473684210526315, correct 54/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5397, AUC: 0.8887, Accuracy: 0.7333
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.6785714285714286, correct 19/28
              precision    recall  f1-score    support
0              0.608696  0.823529  0.700000  17.000000
1              0.863636  0.678571  0.760000  28.000000
accuracy       0.733333  0.733333  0.733333   0.733333
macro avg      0.736166  0.751050  0.730000  45.000000
weighted avg   0.767325  0.733333  0.737333  45.000000
[[14  3]
 [ 9 19]]
Sensitivity:  0.6785714285714286
Specificity:  0.8235294117647058
Epoch 35/50
----------
Training batch 0/107- batch 0, loss: 1.0486, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0149, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0212, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0082, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0044, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0419, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.3900, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0011, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0252, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0857, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0030, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 35, train_loss: 0.0103, train_accuracy: 0.9238
class 0: acc 0.8958333333333334, correct 43/48
class 1: acc 0.9473684210526315, correct 54/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.7952, AUC: 0.8340, Accuracy: 0.6889
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.6071428571428571, correct 17/28
              precision    recall  f1-score    support
0              0.560000  0.823529  0.666667  17.000000
1              0.850000  0.607143  0.708333  28.000000
accuracy       0.688889  0.688889  0.688889   0.688889
macro avg      0.705000  0.715336  0.687500  45.000000
weighted avg   0.740444  0.688889  0.692593  45.000000
[[14  3]
 [11 17]]
Sensitivity:  0.6071428571428571
Specificity:  0.8235294117647058
Epoch 36/50
----------
Training batch 0/107- batch 0, loss: 1.1916, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0193, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0401, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0128, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0037, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0304, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0748, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0001, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0029, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0001, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0259, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 36, train_loss: 0.0033, train_accuracy: 0.9333
class 0: acc 0.9166666666666666, correct 44/48
class 1: acc 0.9473684210526315, correct 54/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.4483, AUC: 0.8803, Accuracy: 0.8444
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.8571428571428571, correct 24/28
              precision    recall  f1-score    support
0              0.777778  0.823529  0.800000  17.000000
1              0.888889  0.857143  0.872727  28.000000
accuracy       0.844444  0.844444  0.844444   0.844444
macro avg      0.833333  0.840336  0.836364  45.000000
weighted avg   0.846914  0.844444  0.845253  45.000000
[[14  3]
 [ 4 24]]
Sensitivity:  0.8571428571428571
Specificity:  0.8235294117647058
Epoch 37/50
----------
Training batch 0/107- batch 0, loss: 2.1452, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0611, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0985, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0256, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0078, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0571, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0087, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0001, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0128, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0418, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0217, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 37, train_loss: 0.0133, train_accuracy: 0.9048
class 0: acc 0.875, correct 42/48
class 1: acc 0.9298245614035088, correct 53/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5354, AUC: 0.8676, Accuracy: 0.8000
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.7857142857142857, correct 22/28
              precision    recall  f1-score  support
0                 0.700  0.823529  0.756757     17.0
1                 0.880  0.785714  0.830189     28.0
accuracy          0.800  0.800000  0.800000      0.8
macro avg         0.790  0.804622  0.793473     45.0
weighted avg      0.812  0.800000  0.802448     45.0
[[14  3]
 [ 6 22]]
Sensitivity:  0.7857142857142857
Specificity:  0.8235294117647058
Epoch 38/50
----------
Training batch 0/107- batch 0, loss: 1.2348, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0337, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0731, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0229, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0038, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0730, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0045, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0007, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0114, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0098, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 38, train_loss: 0.0005, train_accuracy: 0.9524
class 0: acc 0.9375, correct 45/48
class 1: acc 0.9649122807017544, correct 55/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5784, AUC: 0.8803, Accuracy: 0.7778
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.75, correct 21/28
              precision    recall  f1-score    support
0              0.666667  0.823529  0.736842  17.000000
1              0.875000  0.750000  0.807692  28.000000
accuracy       0.777778  0.777778  0.777778   0.777778
macro avg      0.770833  0.786765  0.772267  45.000000
weighted avg   0.796296  0.777778  0.780927  45.000000
[[14  3]
 [ 7 21]]
Sensitivity:  0.75
Specificity:  0.8235294117647058
Epoch 39/50
----------
Training batch 0/107- batch 0, loss: 3.0072, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0184, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.6212, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0184, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0001, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0183, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0002, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0010, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0001, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0099, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 39, train_loss: 0.0011, train_accuracy: 0.9619
class 0: acc 0.9375, correct 45/48
class 1: acc 0.9824561403508771, correct 56/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.9111, AUC: 0.8046, Accuracy: 0.7111
class 0: acc 0.7058823529411765, correct 12/17
class 1: acc 0.7142857142857143, correct 20/28
              precision    recall  f1-score    support
0              0.600000  0.705882  0.648649  17.000000
1              0.800000  0.714286  0.754717  28.000000
accuracy       0.711111  0.711111  0.711111   0.711111
macro avg      0.700000  0.710084  0.701683  45.000000
weighted avg   0.724444  0.711111  0.714647  45.000000
[[12  5]
 [ 8 20]]
Sensitivity:  0.7142857142857143
Specificity:  0.7058823529411765
Epoch 40/50
----------
Training batch 0/107- batch 0, loss: 2.9088, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0014, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.2079, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0582, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0002, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 1.6302, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0057, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0001, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0428, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0087, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0031, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 40, train_loss: 0.0018, train_accuracy: 0.9048
class 0: acc 0.875, correct 42/48
class 1: acc 0.9298245614035088, correct 53/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.8070, AUC: 0.8256, Accuracy: 0.7111
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.6428571428571429, correct 18/28
              precision    recall  f1-score    support
0              0.583333  0.823529  0.682927  17.000000
1              0.857143  0.642857  0.734694  28.000000
accuracy       0.711111  0.711111  0.711111   0.711111
macro avg      0.720238  0.733193  0.708810  45.000000
weighted avg   0.753704  0.711111  0.715137  45.000000
[[14  3]
 [10 18]]
Sensitivity:  0.6428571428571429
Specificity:  0.8235294117647058
Epoch 41/50
----------
Training batch 0/107- batch 0, loss: 1.0174, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0134, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0128, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0221, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0013, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0358, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0011, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0146, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0089, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0235, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 41, train_loss: 0.0094, train_accuracy: 0.9333
class 0: acc 0.9166666666666666, correct 44/48
class 1: acc 0.9473684210526315, correct 54/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.8493, AUC: 0.8088, Accuracy: 0.7556
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.7142857142857143, correct 20/28
              precision    recall  f1-score    support
0              0.636364  0.823529  0.717949  17.000000
1              0.869565  0.714286  0.784314  28.000000
accuracy       0.755556  0.755556  0.755556   0.755556
macro avg      0.752964  0.768908  0.751131  45.000000
weighted avg   0.781467  0.755556  0.759243  45.000000
[[14  3]
 [ 8 20]]
Sensitivity:  0.7142857142857143
Specificity:  0.8235294117647058
Epoch 42/50
----------
Training batch 0/107- batch 0, loss: 1.4041, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0146, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0145, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0969, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0087, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0169, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0031, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.1021, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0000, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0124, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 42, train_loss: 0.0007, train_accuracy: 0.9333
class 0: acc 0.9375, correct 45/48
class 1: acc 0.9298245614035088, correct 53/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.6566, AUC: 0.8445, Accuracy: 0.8000
class 0: acc 0.7647058823529411, correct 13/17
class 1: acc 0.8214285714285714, correct 23/28
              precision    recall  f1-score  support
0              0.722222  0.764706  0.742857     17.0
1              0.851852  0.821429  0.836364     28.0
accuracy       0.800000  0.800000  0.800000      0.8
macro avg      0.787037  0.793067  0.789610     45.0
weighted avg   0.802881  0.800000  0.801039     45.0
[[13  4]
 [ 5 23]]
Sensitivity:  0.8214285714285714
Specificity:  0.7647058823529411
Epoch 43/50
----------
Training batch 0/107- batch 0, loss: 2.0410, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0273, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.1112, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1103, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0060, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0395, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0097, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0395, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0059, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0116, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 43, train_loss: 0.0001, train_accuracy: 0.9524
class 0: acc 0.9375, correct 45/48
class 1: acc 0.9649122807017544, correct 55/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.9201, AUC: 0.8109, Accuracy: 0.7333
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.6428571428571429, correct 18/28
              precision    recall  f1-score    support
0              0.600000  0.882353  0.714286  17.000000
1              0.900000  0.642857  0.750000  28.000000
accuracy       0.733333  0.733333  0.733333   0.733333
macro avg      0.750000  0.762605  0.732143  45.000000
weighted avg   0.786667  0.733333  0.736508  45.000000
[[15  2]
 [10 18]]
Sensitivity:  0.6428571428571429
Specificity:  0.8823529411764706
Epoch 44/50
----------
Training batch 0/107- batch 0, loss: 2.5450, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0182, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0218, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0442, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0124, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0758, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0107, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0021, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0068, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0084, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 44, train_loss: 0.0004, train_accuracy: 0.9524
class 0: acc 0.9375, correct 45/48
class 1: acc 0.9649122807017544, correct 55/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.8557, AUC: 0.8298, Accuracy: 0.7333
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.6428571428571429, correct 18/28
              precision    recall  f1-score    support
0              0.600000  0.882353  0.714286  17.000000
1              0.900000  0.642857  0.750000  28.000000
accuracy       0.733333  0.733333  0.733333   0.733333
macro avg      0.750000  0.762605  0.732143  45.000000
weighted avg   0.786667  0.733333  0.736508  45.000000
[[15  2]
 [10 18]]
Sensitivity:  0.6428571428571429
Specificity:  0.8823529411764706
Epoch 45/50
----------
Training batch 0/107- batch 0, loss: 2.6954, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0289, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0141, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0160, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0032, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0107, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0020, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0004, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0127, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0000, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0248, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 45, train_loss: 0.0014, train_accuracy: 0.9524
class 0: acc 0.9375, correct 45/48
class 1: acc 0.9649122807017544, correct 55/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.7486, AUC: 0.8571, Accuracy: 0.7778
class 0: acc 0.7647058823529411, correct 13/17
class 1: acc 0.7857142857142857, correct 22/28
              precision    recall  f1-score    support
0              0.684211  0.764706  0.722222  17.000000
1              0.846154  0.785714  0.814815  28.000000
accuracy       0.777778  0.777778  0.777778   0.777778
macro avg      0.765182  0.775210  0.768519  45.000000
weighted avg   0.784975  0.777778  0.779835  45.000000
[[13  4]
 [ 6 22]]
Sensitivity:  0.7857142857142857
Specificity:  0.7647058823529411
Epoch 46/50
----------
Training batch 0/107- batch 0, loss: 1.9931, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0989, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0260, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.1127, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0011, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0137, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0034, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0049, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0173, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0051, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 46, train_loss: 0.0002, train_accuracy: 0.9333
class 0: acc 0.9375, correct 45/48
class 1: acc 0.9298245614035088, correct 53/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.9674, AUC: 0.8298, Accuracy: 0.7111
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.6071428571428571, correct 17/28
              precision    recall  f1-score    support
0              0.576923  0.882353  0.697674  17.000000
1              0.894737  0.607143  0.723404  28.000000
accuracy       0.711111  0.711111  0.711111   0.711111
macro avg      0.735830  0.744748  0.710539  45.000000
weighted avg   0.774674  0.711111  0.713684  45.000000
[[15  2]
 [11 17]]
Sensitivity:  0.6071428571428571
Specificity:  0.8823529411764706
Epoch 47/50
----------
Training batch 0/107- batch 0, loss: 0.3603, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0345, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0718, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0489, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0096, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0164, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0071, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0120, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0002, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0188, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 47, train_loss: 0.0004, train_accuracy: 0.9524
class 0: acc 0.9583333333333334, correct 46/48
class 1: acc 0.9473684210526315, correct 54/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.7359, AUC: 0.8361, Accuracy: 0.8000
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.7857142857142857, correct 22/28
              precision    recall  f1-score  support
0                 0.700  0.823529  0.756757     17.0
1                 0.880  0.785714  0.830189     28.0
accuracy          0.800  0.800000  0.800000      0.8
macro avg         0.790  0.804622  0.793473     45.0
weighted avg      0.812  0.800000  0.802448     45.0
[[14  3]
 [ 6 22]]
Sensitivity:  0.7857142857142857
Specificity:  0.8235294117647058
Epoch 48/50
----------
Training batch 0/107- batch 0, loss: 3.1193, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0061, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0649, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0249, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0084, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0445, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0123, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0069, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.0126, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0162, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0173, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 48, train_loss: 0.0003, train_accuracy: 0.9524
class 0: acc 0.9583333333333334, correct 46/48
class 1: acc 0.9473684210526315, correct 54/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.7659, AUC: 0.8109, Accuracy: 0.7778
class 0: acc 0.8823529411764706, correct 15/17
class 1: acc 0.7142857142857143, correct 20/28
              precision    recall  f1-score    support
0              0.652174  0.882353  0.750000  17.000000
1              0.909091  0.714286  0.800000  28.000000
accuracy       0.777778  0.777778  0.777778   0.777778
macro avg      0.780632  0.798319  0.775000  45.000000
weighted avg   0.812033  0.777778  0.781111  45.000000
[[15  2]
 [ 8 20]]
Sensitivity:  0.7142857142857143
Specificity:  0.8823529411764706
Epoch 49/50
----------
Training batch 0/107- batch 0, loss: 0.9716, label: 0, bag_size: 407
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.0298, label: 0, bag_size: 161
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.0257, label: 0, bag_size: 364
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.0155, label: 0, bag_size: 487
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.0090, label: 0, bag_size: 30
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.0216, label: 1, bag_size: 434
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.0196, label: 0, bag_size: 308
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.0000, label: 1, bag_size: 484
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.1174, label: 1, bag_size: 444
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.0281, label: 1, bag_size: 234
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 0.0301, label: 0, bag_size: 204
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 49, train_loss: 0.0017, train_accuracy: 0.9333
class 0: acc 0.9166666666666666, correct 44/48
class 1: acc 0.9473684210526315, correct 54/57
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.6539, AUC: 0.8277, Accuracy: 0.8000
class 0: acc 0.8235294117647058, correct 14/17
class 1: acc 0.7857142857142857, correct 22/28
              precision    recall  f1-score  support
0                 0.700  0.823529  0.756757     17.0
1                 0.880  0.785714  0.830189     28.0
accuracy          0.800  0.800000  0.800000      0.8
macro avg         0.790  0.804622  0.793473     45.0
weighted avg      0.812  0.800000  0.802448     45.0
[[14  3]
 [ 6 22]]
Sensitivity:  0.7857142857142857
Specificity:  0.8235294117647058

Training completed in 584m 51s
CD20
Epoch 0/50
----------
Training batch 0/107- batch 0, loss: 0.7283, label: 0, bag_size: 1332
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.6961, label: 0, bag_size: 426
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.7230, label: 0, bag_size: 72
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.7110, label: 0, bag_size: 453
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.7135, label: 0, bag_size: 36
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.6614, label: 1, bag_size: 1161
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.6957, label: 0, bag_size: 336
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.6611, label: 1, bag_size: 457
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.6037, label: 1, bag_size: 698
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.4953, label: 1, bag_size: 219
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 1.0306, label: 0, bag_size: 202
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 0, train_loss: 0.0100, train_accuracy: 0.5149
class 0: acc 0.021739130434782608, correct 1/46
class 1: acc 0.9272727272727272, correct 51/55
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.6358, AUC: 0.6674, Accuracy: 0.6364
class 0: acc 0.0, correct 0/16
class 1: acc 1.0, correct 28/28
              precision    recall  f1-score    support
0              1.000000  0.000000  0.000000  16.000000
1              0.636364  1.000000  0.777778  28.000000
accuracy       0.636364  0.636364  0.636364   0.636364
macro avg      0.818182  0.500000  0.388889  44.000000
weighted avg   0.768595  0.636364  0.494949  44.000000
[[ 0 16]
 [ 0 28]]
Sensitivity:  1.0
Specificity:  0.0
Epoch 1/50
----------
Training batch 0/107- batch 0, loss: 0.9017, label: 0, bag_size: 1332
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.8135, label: 0, bag_size: 426
Training batch 11/107Training batch 12/107Training batch 13/107Training batch 14/107Training batch 15/107Training batch 16/107Training batch 17/107Training batch 18/107Training batch 19/107Training batch 20/107- batch 20, loss: 0.7425, label: 0, bag_size: 72
Training batch 21/107Training batch 22/107Training batch 23/107Training batch 24/107Training batch 25/107Training batch 26/107Training batch 27/107Training batch 28/107Training batch 29/107Training batch 30/107- batch 30, loss: 0.9912, label: 0, bag_size: 453
Training batch 31/107Training batch 32/107Training batch 33/107Training batch 34/107Training batch 35/107Training batch 36/107Training batch 37/107Training batch 38/107Training batch 39/107Training batch 40/107- batch 40, loss: 0.8476, label: 0, bag_size: 36
Training batch 41/107Training batch 42/107Training batch 43/107Training batch 44/107Training batch 45/107Training batch 46/107Training batch 47/107Training batch 48/107Training batch 49/107Training batch 50/107- batch 50, loss: 0.3162, label: 1, bag_size: 1161
Training batch 51/107Training batch 52/107Training batch 53/107Training batch 54/107Training batch 55/107Training batch 56/107Training batch 57/107Training batch 58/107Training batch 59/107Training batch 60/107- batch 60, loss: 0.6727, label: 0, bag_size: 336
Training batch 61/107Training batch 62/107Training batch 63/107Training batch 64/107Training batch 65/107Training batch 66/107Training batch 67/107Training batch 68/107Training batch 69/107Training batch 70/107- batch 70, loss: 0.3053, label: 1, bag_size: 457
Training batch 71/107Training batch 72/107Training batch 73/107Training batch 74/107Training batch 75/107Training batch 76/107Training batch 77/107Training batch 78/107Training batch 79/107Training batch 80/107- batch 80, loss: 0.3764, label: 1, bag_size: 698
Training batch 81/107Training batch 82/107Training batch 83/107Training batch 84/107Training batch 85/107Training batch 86/107Training batch 87/107Training batch 88/107Training batch 89/107Training batch 90/107- batch 90, loss: 0.1153, label: 1, bag_size: 219
Training batch 91/107Training batch 92/107Training batch 93/107Training batch 94/107Training batch 95/107Training batch 96/107Training batch 97/107Training batch 98/107Training batch 99/107Training batch 100/107- batch 100, loss: 1.1140, label: 0, bag_size: 202
Training batch 101/107Training batch 102/107Training batch 103/107Training batch 104/107Training batch 105/107Training batch 106/107
Epoch: 1, train_loss: 0.0070, train_accuracy: 0.5347
class 0: acc 0.10869565217391304, correct 5/46
class 1: acc 0.8909090909090909, correct 49/55
Validation batch 0/46Validation batch 1/46Validation batch 2/46Validation batch 3/46Validation batch 4/46Validation batch 5/46Validation batch 6/46Validation batch 7/46Validation batch 8/46Validation batch 9/46Validation batch 10/46Validation batch 11/46Validation batch 12/46Validation batch 13/46Validation batch 14/46Validation batch 15/46Validation batch 16/46Validation batch 17/46Validation batch 18/46Validation batch 19/46Validation batch 20/46Validation batch 21/46Validation batch 22/46Validation batch 23/46Validation batch 24/46Validation batch 25/46Validation batch 26/46Validation batch 27/46Validation batch 28/46Validation batch 29/46Validation batch 30/46Validation batch 31/46Validation batch 32/46Validation batch 33/46Validation batch 34/46Validation batch 35/46Validation batch 36/46Validation batch 37/46Validation batch 38/46Validation batch 39/46Validation batch 40/46Validation batch 41/46Validation batch 42/46Validation batch 43/46Validation batch 44/46Validation batch 45/46
Val Set, val_loss: 0.5719, AUC: 0.7388, Accuracy: 0.6591
class 0: acc 0.125, correct 2/16
class 1: acc 0.9642857142857143, correct 27/28
              precision    recall  f1-score    support
0              0.666667  0.125000  0.210526  16.000000
1              0.658537  0.964286  0.782609  28.000000
accuracy       0.659091  0.659091  0.659091   0.659091
macro avg      0.662602  0.544643  0.496568  44.000000
weighted avg   0.661493  0.659091  0.574579  44.000000
[[ 2 14]
 [ 1 27]]
Sensitivity:  0.9642857142857143
Specificity:  0.125
Epoch 2/50
----------
Training batch 0/107- batch 0, loss: 1.1648, label: 0, bag_size: 1332
Training batch 1/107Training batch 2/107Training batch 3/107Training batch 4/107Training batch 5/107Training batch 6/107Training batch 7/107Training batch 8/107Training batch 9/107Training batch 10/107- batch 10, loss: 0.6647, label: 0, bag_size: 426
Training batch 11/107Training batch 12/107